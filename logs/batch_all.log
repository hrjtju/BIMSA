rule: B3/S23 \t, network: small_2_layer_seq_p4cnn \n\n
./predictor_life_simple/hyperparams/small_2_layer_seq_p4cnn.toml

{'info': 'Baseline model with default hyperparameters', 'wandb': {'turn_on': True, 'entity': 'small_2_layer_seq_p4cnn'}, 'dataloader': {'train_batch_size': 8, 'train_num_workers': 4, 'train_shuffle': True, 'test_batch_size': 8, 'test_num_workers': 4, 'test_shuffle': False}, 'optimizer': {'name': 'AdamW', 'args': {'lr': 0.001}}, 'lr_scheduler': {'name': 'CyclicLR', 'args': {'base_lr': 0.001, 'max_lr': 0.05, 'step_size_up': 50, 'step_size_down': 10}}, 'model': {'name': 'SimpleP4CNNSmall'}, 'training': {'epochs': 8, 'r_ratio_start': 1, 'r_ratio_decay': 1e-05, 'r_ratio_min': 0.01}, 'hyperparameters': './predictor_life_simple/hyperparams/small_2_layer_seq_p4cnn.toml', 'data_rule': 'B3/S23', 'data_iters': 200, 'sys_size': 200}
Starting training...

Picking Dataset: ./predictor_life_simple/datasets/200-200-B3_S23/
Saving Base Directory: 2025-10-16_16-49-44_small_2_layer_seq_p4cnn__200-200-B3_S23


====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
SimpleP4CNNSmall                                   --                        --
©À©¤R2Conv: 1-1                                      --                        176
©¦    ©¸©¤BlocksBasisExpansion: 2-1                   --                        --
©¦    ©¦    ©¸©¤SingleBlockBasisExpansion: 3-1         --                        --
©À©¤InnerBatchNorm: 1-2                              --                        --
©¦    ©¸©¤BatchNorm3d: 2-2                            --                        16
©À©¤ReLU: 1-3                                        --                        --
©À©¤R2Conv: 1-4                                      --                        2,816
©¦    ©¸©¤BlocksBasisExpansion: 2-3                   --                        --
©¦    ©¦    ©¸©¤SingleBlockBasisExpansion: 3-2         --                        --
©À©¤InnerBatchNorm: 1-5                              --                        --
©¦    ©¸©¤BatchNorm3d: 2-4                            --                        16
©À©¤ReLU: 1-6                                        --                        --
©À©¤R2Conv: 1-7                                      --                        178
©¦    ©¸©¤BlocksBasisExpansion: 2-5                   --                        --
©¦    ©¦    ©¸©¤SingleBlockBasisExpansion: 3-3         --                        --
====================================================================================================
Total params: 3,202
Trainable params: 3,202
Non-trainable params: 0
Total mult-adds (M): 0
====================================================================================================
Input size (MB): 0.32
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 0.32
====================================================================================================
Epoch 1/8
----------
| 2025-10-16 16:50:05.567207 | Idx:   40/400    | loss: 0.540 | grad_norm: 1.695 | acc: 95.15% |
| 2025-10-16 16:50:13.705155 | Idx:   80/400    | loss: 0.406 | grad_norm: 1.157 | acc: 94.96% |
| 2025-10-16 16:50:23.174017 | Idx:  120/400    | loss: 0.317 | grad_norm: 0.709 | acc: 97.13% |
| 2025-10-16 16:50:31.446926 | Idx:  160/400    | loss: 0.257 | grad_norm: 1.981 | acc: 99.17% |
| 2025-10-16 16:50:39.680778 | Idx:  200/400    | loss: 0.217 | grad_norm: 0.220 | acc: 99.54% |
| 2025-10-16 16:50:49.162656 | Idx:  240/400    | loss: 0.185 | grad_norm: 0.832 | acc: 98.07% |
| 2025-10-16 16:50:57.591625 | Idx:  280/400    | loss: 0.166 | grad_norm: 0.233 | acc: 99.96% |
| 2025-10-16 16:51:07.132885 | Idx:  320/400    | loss: 0.148 | grad_norm: 0.087 | acc: 99.91% |
| 2025-10-16 16:51:14.947259 | Idx:  360/400    | loss: 0.134 | grad_norm: 0.077 | acc: 99.89% |
| 2025-10-16 16:51:23.030396 | Idx:  400/400    | loss: 0.124 | grad_norm: 0.574 | acc: 99.87% |
Train Loss: 0.1237 Acc: 97.52%
Acc: 99.99%
Epoch 2/8
----------
| 2025-10-16 16:51:54.883262 | Idx:   40/400    | loss: 0.016 | grad_norm: 0.075 | acc: 99.96% |
| 2025-10-16 16:52:03.133376 | Idx:   80/400    | loss: 0.012 | grad_norm: 0.293 | acc: 99.67% |
| 2025-10-16 16:52:12.399416 | Idx:  120/400    | loss: 0.011 | grad_norm: 0.023 | acc: 99.99% |
| 2025-10-16 16:52:20.237724 | Idx:  160/400    | loss: 0.010 | grad_norm: 0.019 | acc: 100.00% |
| 2025-10-16 16:52:28.027529 | Idx:  200/400    | loss: 0.010 | grad_norm: 0.042 | acc: 99.97% |
| 2025-10-16 16:52:37.418205 | Idx:  240/400    | loss: 0.010 | grad_norm: 0.051 | acc: 100.00% |
| 2025-10-16 16:52:45.225465 | Idx:  280/400    | loss: 0.010 | grad_norm: 0.035 | acc: 99.98% |
| 2025-10-16 16:52:54.330365 | Idx:  320/400    | loss: 0.009 | grad_norm: 0.037 | acc: 99.99% |
| 2025-10-16 16:53:02.146037 | Idx:  360/400    | loss: 0.008 | grad_norm: 0.012 | acc: 100.00% |
| 2025-10-16 16:53:09.854556 | Idx:  400/400    | loss: 0.009 | grad_norm: 0.061 | acc: 99.95% |
Train Loss: 0.0090 Acc: 99.92%
Acc: 99.94%
Epoch 3/8
----------
| 2025-10-16 16:53:41.227075 | Idx:   40/400    | loss: 0.064 | grad_norm: 0.522 | acc: 98.92% |
| 2025-10-16 16:53:48.879915 | Idx:   80/400    | loss: 0.045 | grad_norm: 0.102 | acc: 99.82% |
| 2025-10-16 16:53:57.832253 | Idx:  120/400    | loss: 0.033 | grad_norm: 0.022 | acc: 100.00% |
| 2025-10-16 16:54:05.560915 | Idx:  160/400    | loss: 0.044 | grad_norm: 0.676 | acc: 98.20% |
| 2025-10-16 16:54:13.353912 | Idx:  200/400    | loss: 0.038 | grad_norm: 0.003 | acc: 100.00% |
| 2025-10-16 16:54:23.608926 | Idx:  240/400    | loss: 0.034 | grad_norm: 0.002 | acc: 100.00% |
| 2025-10-16 16:54:34.391835 | Idx:  280/400    | loss: 0.030 | grad_norm: 0.077 | acc: 99.99% |
| 2025-10-16 16:54:45.753700 | Idx:  320/400    | loss: 0.027 | grad_norm: 0.001 | acc: 100.00% |
| 2025-10-16 16:54:55.700990 | Idx:  360/400    | loss: 0.026 | grad_norm: 0.006 | acc: 100.00% |
| 2025-10-16 16:55:05.540657 | Idx:  400/400    | loss: 0.024 | grad_norm: 0.003 | acc: 100.00% |
Train Loss: 0.0239 Acc: 99.67%
Acc: 100.00%
